{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/artem/.local/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    " \n",
    "def load_df(path, kind='train'):\n",
    "    labels_path = os.path.join(path, '%s_labels.idx1-ubyte' % kind)\n",
    "    images_path = os.path.join(path, '%s_images.idx3-ubyte' % kind)\n",
    "        \n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II', lbpath.read(8))\n",
    "        labels = np.fromfile(lbpath, dtype=np.uint8)\n",
    "\n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", imgpath.read(16))\n",
    "        images = np.fromfile(imgpath, dtype=np.uint8).reshape(len(labels), 784)\n",
    "        images = ((images / 255.) - .5) * 2 # нормализация пикселей в диапазон [-1, 1]\n",
    " \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN df: Rows: 60000, columns: 784\n",
      "TEST  df: Rows: 10000, columns: 784\n",
      "(60000, 784) (60000,)\n",
      "(10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_df('image_data', kind='train')\n",
    "print('TRAIN df: Rows: %d, columns: %d' % (X_train.shape))\n",
    "\n",
    "X_test, y_test = load_df('image_data', kind='test')\n",
    "print('TEST  df: Rows: %d, columns: %d' % (X_test.shape))\n",
    "\n",
    "# центрирование по среднему и нормализация\n",
    "mean_vals = np.mean(X_train, axis=0)\n",
    "std_val = np.std(X_train)\n",
    "\n",
    "X_train_centered = (X_train - mean_vals)/std_val\n",
    "X_test_centered = (X_test - mean_vals)/std_val\n",
    "\n",
    "del X_train, X_test\n",
    "print(X_train_centered.shape, y_train.shape)\n",
    "print(X_test_centered.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Neural Networks with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-cef6b955e0d2>:19: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /home/artem/.local/lib/python3.6/site-packages/tensorflow/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    }
   ],
   "source": [
    "n_features = X_train_centered.shape[1]\n",
    "n_classes = 10\n",
    "random_seed = 123\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    tf.set_random_seed(random_seed)\n",
    "    tf_x = tf.placeholder(dtype=tf.float32,\n",
    "                          shape=(None, n_features),\n",
    "                          name='tf_x')\n",
    "\n",
    "    tf_y = tf.placeholder(dtype=tf.int32, \n",
    "                          shape=None, name='tf_y')\n",
    "    y_onehot = tf.one_hot(indices=tf_y, depth=n_classes)\n",
    "\n",
    "    h1 = tf.layers.dense(inputs=tf_x, units=50,    # 1 скрытый слой\n",
    "                         activation=tf.tanh,\n",
    "                         name='layer1')\n",
    "\n",
    "    h2 = tf.layers.dense(inputs=h1, units=50,      # 2 скрытый слой\n",
    "                         activation=tf.tanh,\n",
    "                         name='layer2')\n",
    "\n",
    "    logits = tf.layers.dense(inputs=h2, \n",
    "                             units=10,\n",
    "                             activation=None,\n",
    "                             name='layer3')\n",
    "\n",
    "    predictions = {\n",
    "        'classes'       : tf.argmax(logits, axis=1, name='predicted_classes'),\n",
    "        'probabilities' : tf.nn.softmax(logits,     name='softmax_tensor')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определение функции издержек и операции оптимизации\n",
    "with g.as_default():\n",
    "    cost = tf.losses.softmax_cross_entropy(\n",
    "            onehot_labels=y_onehot, logits=logits)\n",
    "\n",
    "    optimizer = tf.train.GradientDescentOptimizer(\n",
    "            learning_rate=0.001)\n",
    "\n",
    "    train_op = optimizer.minimize(loss=cost)\n",
    "\n",
    "    init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch_generator(X, y, batch_size=128, shuffle=False):\n",
    "    X_copy = np.array(X)\n",
    "    y_copy = np.array(y)\n",
    "    \n",
    "    if shuffle:\n",
    "        data = np.column_stack((X_copy, y_copy))\n",
    "        np.random.shuffle(data)\n",
    "        X_copy = data[:, :-1]\n",
    "        y_copy = data[:, -1].astype(int)\n",
    "    \n",
    "    for i in range(0, X.shape[0], batch_size):\n",
    "        yield (X_copy[i:i+batch_size, :], y_copy[i:i+batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ~~  1  средние потери при обучение: 1.5841\n",
      " ~~  2  средние потери при обучение: 1.2739\n",
      " ~~  3  средние потери при обучение: 1.1002\n",
      " ~~  4  средние потери при обучение: 0.9846\n",
      " ~~  5  средние потери при обучение: 0.9005\n",
      " ~~  6  средние потери при обучение: 0.8360\n",
      " ~~  7  средние потери при обучение: 0.7845\n",
      " ~~  8  средние потери при обучение: 0.7422\n",
      " ~~  9  средние потери при обучение: 0.7067\n",
      " ~~ 10  средние потери при обучение: 0.6764\n",
      " ~~ 11  средние потери при обучение: 0.6501\n",
      " ~~ 12  средние потери при обучение: 0.6271\n",
      " ~~ 13  средние потери при обучение: 0.6066\n",
      " ~~ 14  средние потери при обучение: 0.5884\n",
      " ~~ 15  средние потери при обучение: 0.5719\n",
      " ~~ 16  средние потери при обучение: 0.5569\n",
      " ~~ 17  средние потери при обучение: 0.5433\n",
      " ~~ 18  средние потери при обучение: 0.5308\n",
      " ~~ 19  средние потери при обучение: 0.5192\n",
      " ~~ 20  средние потери при обучение: 0.5085\n",
      " ~~ 21  средние потери при обучение: 0.4985\n",
      " ~~ 22  средние потери при обучение: 0.4892\n",
      " ~~ 23  средние потери при обучение: 0.4805\n",
      " ~~ 24  средние потери при обучение: 0.4724\n",
      " ~~ 25  средние потери при обучение: 0.4647\n"
     ]
    }
   ],
   "source": [
    "# Создание сессия для запуска графа\n",
    "sess =  tf.Session(graph=g)\n",
    "# инициализация переменных\n",
    "sess.run(init_op)\n",
    "\n",
    "# 15 итераций обучения\n",
    "training_costs = []\n",
    "for epoch in range(15):\n",
    "    training_loss = []\n",
    "    batch_generator = create_batch_generator(\n",
    "            X_train_centered, y_train, \n",
    "            batch_size=64)\n",
    "    for batch_X, batch_y in batch_generator:\n",
    "        ## подготовка словаря для передачи данных се\n",
    "        feed = {tf_x:batch_X, tf_y:batch_y}\n",
    "        _, batch_cost = sess.run([train_op, cost],\n",
    "                                 feed_dict=feed)\n",
    "        training_costs.append(batch_cost)\n",
    "    print(' ~~ %2d  '\n",
    "          'средние потери при обучение: %.4f' % (\n",
    "              epoch+1, np.mean(training_costs)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Правильность при испытании: 92.37%\n"
     ]
    }
   ],
   "source": [
    "feed = {tf_x : X_test_centered}\n",
    "y_pred = sess.run(predictions['classes'], feed_dict=feed)\n",
    "acc = np.sum(y_pred == y_test)/len(y_test)\n",
    "print(f'Правильность при испытании: {acc:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Neural Networks with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "\n",
    "np.random.seed(123)\n",
    "tf.set_random_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Превые 3 метки:  [5 0 4]\n",
      "\n",
      "Превые 3 метки (one-hot):\n",
      " [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "y_train_onehot = keras.utils.to_categorical(y_train)\n",
    " \n",
    "print('Превые 3 метки: ', y_train[:3])\n",
    "print('\\nПревые 3 метки (one-hot):\\n', y_train_onehot[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/artem/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()  # для NN прямого распространения \n",
    "\n",
    "model.add(  #  входной слой                              \n",
    "    keras.layers.Dense(\n",
    "        units=50,\n",
    "        input_dim=X_train_centered.shape[1],\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='tanh'))\n",
    "\n",
    "model.add(  #  1 скрытый слой\n",
    "    keras.layers.Dense(\n",
    "        units=50,\n",
    "        input_dim=50,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='tanh'))\n",
    "\n",
    "model.add(  #  2 скрытый слой\n",
    "    keras.layers.Dense(\n",
    "        units=y_train_onehot.shape[1],\n",
    "        input_dim=50,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='softmax'))\n",
    "\n",
    "sgd_optimizer = keras.optimizers.SGD(\n",
    "    lr=0.001, decay=1e-7, momentum=.9)\n",
    "\n",
    "# функция потерь\n",
    "model.compile(optimizer=sgd_optimizer, \n",
    "              loss='categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/50\n",
      "54000/54000 [==============================] - 3s 48us/sample - loss: 0.7370 - val_loss: 0.3618\n",
      "Epoch 2/50\n",
      "54000/54000 [==============================] - 2s 42us/sample - loss: 0.3656 - val_loss: 0.2734\n",
      "Epoch 3/50\n",
      "54000/54000 [==============================] - 3s 47us/sample - loss: 0.2994 - val_loss: 0.2343\n",
      "Epoch 4/50\n",
      "54000/54000 [==============================] - 3s 50us/sample - loss: 0.2629 - val_loss: 0.2111\n",
      "Epoch 5/50\n",
      "54000/54000 [==============================] - 2s 40us/sample - loss: 0.2377 - val_loss: 0.1941\n",
      "Epoch 6/50\n",
      "54000/54000 [==============================] - 2s 40us/sample - loss: 0.2186 - val_loss: 0.1792\n",
      "Epoch 7/50\n",
      "54000/54000 [==============================] - 2s 44us/sample - loss: 0.2028 - val_loss: 0.1691\n",
      "Epoch 8/50\n",
      "54000/54000 [==============================] - 2s 42us/sample - loss: 0.1897 - val_loss: 0.1610\n",
      "Epoch 9/50\n",
      "54000/54000 [==============================] - 2s 42us/sample - loss: 0.1782 - val_loss: 0.1546\n",
      "Epoch 10/50\n",
      "54000/54000 [==============================] - 2s 45us/sample - loss: 0.1684 - val_loss: 0.1485\n",
      "Epoch 11/50\n",
      "54000/54000 [==============================] - 2s 42us/sample - loss: 0.1593 - val_loss: 0.1432\n",
      "Epoch 12/50\n",
      "54000/54000 [==============================] - 2s 43us/sample - loss: 0.1514 - val_loss: 0.1390\n",
      "Epoch 13/50\n",
      "54000/54000 [==============================] - 3s 48us/sample - loss: 0.1442 - val_loss: 0.1354\n",
      "Epoch 14/50\n",
      "54000/54000 [==============================] - 2s 42us/sample - loss: 0.1377 - val_loss: 0.1323\n",
      "Epoch 15/50\n",
      "54000/54000 [==============================] - 3s 52us/sample - loss: 0.1317 - val_loss: 0.1292\n",
      "Epoch 16/50\n",
      "54000/54000 [==============================] - 2s 42us/sample - loss: 0.1262 - val_loss: 0.1275\n",
      "Epoch 17/50\n",
      "54000/54000 [==============================] - 2s 42us/sample - loss: 0.1212 - val_loss: 0.1244\n",
      "Epoch 18/50\n",
      "54000/54000 [==============================] - 2s 34us/sample - loss: 0.1166 - val_loss: 0.1220\n",
      "Epoch 19/50\n",
      "54000/54000 [==============================] - 2s 37us/sample - loss: 0.1122 - val_loss: 0.1215\n",
      "Epoch 20/50\n",
      "54000/54000 [==============================] - 2s 39us/sample - loss: 0.1083 - val_loss: 0.1195\n",
      "Epoch 21/50\n",
      "54000/54000 [==============================] - 2s 33us/sample - loss: 0.1044 - val_loss: 0.1182\n",
      "Epoch 22/50\n",
      "54000/54000 [==============================] - 2s 34us/sample - loss: 0.1010 - val_loss: 0.1165\n",
      "Epoch 23/50\n",
      "54000/54000 [==============================] - 2s 34us/sample - loss: 0.0976 - val_loss: 0.1154\n",
      "Epoch 24/50\n",
      "54000/54000 [==============================] - 2s 34us/sample - loss: 0.0943 - val_loss: 0.1141\n",
      "Epoch 25/50\n",
      "54000/54000 [==============================] - 2s 36us/sample - loss: 0.0915 - val_loss: 0.1138\n",
      "Epoch 26/50\n",
      "54000/54000 [==============================] - 2s 34us/sample - loss: 0.0885 - val_loss: 0.1121\n",
      "Epoch 27/50\n",
      "54000/54000 [==============================] - 2s 35us/sample - loss: 0.0858 - val_loss: 0.1125\n",
      "Epoch 28/50\n",
      "54000/54000 [==============================] - 2s 35us/sample - loss: 0.0832 - val_loss: 0.1111\n",
      "Epoch 29/50\n",
      "54000/54000 [==============================] - 3s 49us/sample - loss: 0.0807 - val_loss: 0.1109\n",
      "Epoch 30/50\n",
      "54000/54000 [==============================] - 3s 47us/sample - loss: 0.0784 - val_loss: 0.1100\n",
      "Epoch 31/50\n",
      "54000/54000 [==============================] - 3s 48us/sample - loss: 0.0761 - val_loss: 0.1098\n",
      "Epoch 32/50\n",
      "54000/54000 [==============================] - 3s 50us/sample - loss: 0.0740 - val_loss: 0.1098\n",
      "Epoch 33/50\n",
      "54000/54000 [==============================] - 3s 61us/sample - loss: 0.0718 - val_loss: 0.1089\n",
      "Epoch 34/50\n",
      "54000/54000 [==============================] - 3s 56us/sample - loss: 0.0698 - val_loss: 0.1087\n",
      "Epoch 35/50\n",
      "54000/54000 [==============================] - 2s 45us/sample - loss: 0.0679 - val_loss: 0.1091\n",
      "Epoch 36/50\n",
      "54000/54000 [==============================] - 2s 43us/sample - loss: 0.0660 - val_loss: 0.1083\n",
      "Epoch 37/50\n",
      "54000/54000 [==============================] - 2s 44us/sample - loss: 0.0643 - val_loss: 0.1087\n",
      "Epoch 38/50\n",
      "54000/54000 [==============================] - 2s 35us/sample - loss: 0.0625 - val_loss: 0.1085\n",
      "Epoch 39/50\n",
      "54000/54000 [==============================] - 2s 34us/sample - loss: 0.0609 - val_loss: 0.1068\n",
      "Epoch 40/50\n",
      "54000/54000 [==============================] - 2s 34us/sample - loss: 0.0592 - val_loss: 0.1077\n",
      "Epoch 41/50\n",
      "54000/54000 [==============================] - 2s 33us/sample - loss: 0.0576 - val_loss: 0.1078\n",
      "Epoch 42/50\n",
      "54000/54000 [==============================] - 2s 39us/sample - loss: 0.0560 - val_loss: 0.1082\n",
      "Epoch 43/50\n",
      "54000/54000 [==============================] - 3s 46us/sample - loss: 0.0545 - val_loss: 0.1086\n",
      "Epoch 44/50\n",
      "54000/54000 [==============================] - 3s 47us/sample - loss: 0.0532 - val_loss: 0.1089\n",
      "Epoch 45/50\n",
      "54000/54000 [==============================] - 2s 40us/sample - loss: 0.0519 - val_loss: 0.1078\n",
      "Epoch 46/50\n",
      "54000/54000 [==============================] - 2s 41us/sample - loss: 0.0504 - val_loss: 0.1097\n",
      "Epoch 47/50\n",
      "54000/54000 [==============================] - 2s 39us/sample - loss: 0.0492 - val_loss: 0.1089\n",
      "Epoch 48/50\n",
      "54000/54000 [==============================] - 2s 34us/sample - loss: 0.0479 - val_loss: 0.1087\n",
      "Epoch 49/50\n",
      "54000/54000 [==============================] - 2s 39us/sample - loss: 0.0467 - val_loss: 0.1084\n",
      "Epoch 50/50\n",
      "54000/54000 [==============================] - 2s 37us/sample - loss: 0.0456 - val_loss: 0.1090\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_centered, y_train_onehot,\n",
    "                    batch_size=64, epochs=50,\n",
    "                    verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-d717e75eb8ae>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "Первые 3 прогноза:  [5 0 4]\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict_classes(X_train_centered, verbose=0)\n",
    "print('Первые 3 прогноза: ', y_train_pred[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Правильность при обучение: 98.96%\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict_classes(X_train_centered, verbose=0)\n",
    "\n",
    "correct_preds = np.sum(y_train == y_train_pred, axis=0) \n",
    "train_acc = correct_preds / len(y_train)\n",
    "print(f'Правильность при обучении: {train_acc:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Правильность при испытание: 96.39%\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.predict_classes(X_test_centered, verbose=0)\n",
    "\n",
    "correct_preds = np.sum(y_test == y_test_pred, axis=0) \n",
    "test_acc = correct_preds / len(y_test)\n",
    "print(f'Правильность при испытании: {test_acc:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
