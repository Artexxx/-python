{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/artem/.local/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.compat.v1.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Raw shapes: (27455, 785) (7172, 785)\n",
      "\n",
      " New train/test shapes: (27455, 784) (27455, 24) (7172, 784) (7172, 24)\n",
      "\n",
      " Shape 1 example : (784,) (24,)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('MNIST/sign_mnist_train.csv')\n",
    "test_data = pd.read_csv('MNIST/sign_mnist_test.csv')\n",
    "print(\" Raw shapes:\", train_data.shape, test_data.shape)\n",
    "\n",
    "## encoding label\n",
    "encoder = OneHotEncoder() \n",
    "\n",
    "## normalizing train images to standard 0-1 pixel values.\n",
    "x_train = (train_data.iloc[:, 1:]/255).values \n",
    "y_train = encoder.fit_transform(train_data['label'].values.reshape(-1,1)).toarray()\n",
    "\n",
    "## normalizing test images to standard 0-1 pixel values.\n",
    "x_test = (test_data.iloc[:, 1:]/255).values \n",
    "y_test = encoder.fit_transform(test_data['label'].values.reshape(-1,1)).toarray()\n",
    "\n",
    "print(\"\\n New train/test shapes:\", x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "print(\"\\n Shape 1 example :\", x_train[1].shape, y_train[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Weights And Units In Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_width  = 28\n",
    "input_height = 28\n",
    "input_channel = 1\n",
    "input_pixels  = 784\n",
    "\n",
    "n_conv1 = 64\n",
    "n_conv2 = 128\n",
    "stride_conv1 = 1\n",
    "stride_conv2 = 1\n",
    "filter1_k = 5\n",
    "filter2_k = 5\n",
    "maxpool1_k = 2\n",
    "maxpool2_k = 2\n",
    "\n",
    "n_hidden = 1024\n",
    "n_out = 24\n",
    "\n",
    "input_size_to_hidden_layer = \\\n",
    "    ((input_width//(maxpool1_k*maxpool2_k)) *\\\n",
    "    (input_height//(maxpool1_k*maxpool2_k)) * n_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "weight  to convolutional layer1      5 x 5 x 1 x 64\n",
    "weight  to convolutional layer2      5 x 5 x 64 x 128\n",
    "weight  to hidden layer              6272 x 1024\n",
    "weight  to output layer              1024 x 24\n",
    "'''\n",
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([filter1_k, filter1_k, input_channel, n_conv1])), \n",
    "    'wc2': tf.Variable(tf.random_normal([filter2_k, filter2_k, n_conv1, n_conv2])), \n",
    "    'wh' : tf.Variable(tf.random_normal([input_size_to_hidden_layer, n_hidden])),  \n",
    "    'wo' : tf.Variable(tf.random_normal([n_hidden, n_out]))\n",
    "}\n",
    "'''\n",
    "biases  to convolutional layer1     64\n",
    "biases  to convolutional layer2     128\n",
    "biases  to hidden layer             1024\n",
    "biases  to output layer             24\n",
    "'''\n",
    "biases = {\n",
    "    'bc1' : tf.Variable(tf.random_normal([n_conv1])), \n",
    "    'bc2' : tf.Variable(tf.random_normal([n_conv2])), \n",
    "    'bh' : tf.Variable(tf.random_normal([n_hidden])), \n",
    "    'bo' : tf.Variable(tf.random_normal([n_out])) \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для получения выходных данных из сверточного слоя\n",
    "def conv(x, weights, bias, stride = 1):\n",
    "    output = tf.nn.conv2d(x, weights, padding='SAME', strides=[1, stride, stride, 1])\n",
    "    output = tf.nn.bias_add(output, bias)\n",
    "    output = tf.nn.relu(output) # apply activation function\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция, которая возвращает выходные данные объединяющего слоя (pooling layer),\n",
    "# используемого для уменьшения размера изображения, так что мы должны тренировать меньше Весов и смещений\n",
    "def maxpooling(x, k): # k = {2, 5}\n",
    "    return tf.nn.max_pool(\n",
    "           x, padding='SAME',\n",
    "           ksize=[1, k, k, 1],\n",
    "           strides=[1, k, k, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(x, weights, biases):\n",
    "    x = tf.reshape(x, shape = [-1, input_width, input_height, input_channel]) #~> (1, 28, 28, 1)\n",
    "    \n",
    "    conv1 = conv(x, weights['wc1'], biases['bc1'], stride_conv1)\n",
    "    conv1_pool = maxpooling(conv1, maxpool1_k)\n",
    "    \n",
    "    conv2 = conv(conv1_pool, weights['wc2'], biases['bc2'], stride_conv2)\n",
    "    conv2_pool = maxpooling(conv2, maxpool2_k)\n",
    "    \n",
    "    hidden_layer_input = tf.reshape(conv2_pool, shape = [-1, input_size_to_hidden_layer])\n",
    "    hidden_layer_output = tf.nn.relu(tf.add(tf.matmul(hidden_layer_input, weights['wh']), biases['bh']))\n",
    "    \n",
    "    output = tf.add(tf.matmul(hidden_layer_output, weights['wo']), biases['bo'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [ None, input_pixels], name='x')\n",
    "Y = tf.placeholder(tf.int32,   [ None, n_out],        name='y')\n",
    "pred = forward_propagation(X, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels=Y))\n",
    "\n",
    "## adam optimizer on the cost\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.011)\n",
    "optimize  = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## new session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost at 1 iteration: 3.638e+06\n",
      "cost at 2 iteration: 8.83e+03\n",
      "cost at 3 iteration: 3.627e+03\n",
      "cost at 4 iteration: 5.462e+03\n",
      "cost at 5 iteration: 4.078e+03\n",
      "cost at 6 iteration: 4.17e+03\n",
      "cost at 7 iteration: 4.049e+03\n",
      "cost at 8 iteration: 5.477e+03\n",
      "cost at 9 iteration: 5.002e+03\n",
      "cost at 10 iteration: 3.039e+03\n"
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "a = 0\n",
    "\n",
    "for i in range(10):\n",
    "    num_batches = int(len(x_train)/batch_size)\n",
    "    total_cost = 0\n",
    "    for j in range(num_batches):\n",
    "        batch_x = x_train[a: a+batch_size]\n",
    "        batch_y = y_train[a: a+batch_size]\n",
    "        c, _ = sess.run([cost, optimize], feed_dict={X:batch_x, Y:batch_y})\n",
    "        total_cost += c\n",
    "        a += batch_size\n",
    "    a = 0\n",
    "    print(f'cost at {i+1} iteration: {total_cost:.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.87%\n"
     ]
    }
   ],
   "source": [
    "# testing model on training data\n",
    "predictions    = tf.argmax(pred, axis=1)\n",
    "correct_labels = tf.argmax(Y, axis=1)\n",
    "accuracy = tf.equal(predictions, correct_labels)\n",
    "predictions, labels, accuracy = sess.run([predictions, correct_labels, accuracy], feed_dict={X:x_train, Y:y_train})\n",
    "print(f'Accuracy: {accuracy.sum()/len(x_train):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.96%\n"
     ]
    }
   ],
   "source": [
    "# testing model on testing data\n",
    "predictions    = tf.argmax(pred, axis=1)\n",
    "correct_labels = tf.argmax(Y, axis=1)\n",
    "accuracy = tf.equal(predictions, correct_labels)\n",
    "predictions, labels, accuracy = sess.run([predictions, correct_labels, accuracy], feed_dict={X:x_test, Y:y_test})\n",
    "accuracy = accuracy.sum()/len(x_test)\n",
    "print(f'Accuracy: {accuracy:.2%}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
